# coding=utf-8
import cv2
import numpy as np
import os
import csv
import sys
import ConfigParser
import itertools
import collections
import business_geocoder as geo
from math import sqrt
from fuzzywuzzy import fuzz, process
from operator import itemgetter, attrgetter
from sklearn.cluster import KMeans
from threading import Lock

import georeg
from TessBinding import TessBaseAPI

_datadir = os.path.join(georeg.__path__[0], "data")

class CityDetector:
    """loads a file of cities for comparison against strings"""
    def __init__(self):
        self.city_list = []
        
    def load_cities(self, file_name):
        self.city_list = [] # clear old values

        with open(file_name) as file:
            for line in file:
                line = line.strip()
                self.city_list.append(line)

    def match_to_cities(self, line, cutoff=60):
        line = line.lower().strip()

        # if the end of the string matches "â€”continued" then remove it
        if fuzz.ratio(line[-12:], "-continued") > cutoff:
            line = line[:-12]

        match, ratio = process.extractOne(line, self.city_list)

        if ratio > cutoff:
            return match
        else:
            return None

class Business:

    def __init__(self):
        self.name = ""
        self.city = ""
        self.zip = ""
        self.address = ""
        self.category = [] # business category or sic code depending on year
        self.emp = "" # employment
        self.sales = ""
        self.cat_desc = []
        self.bracket = ""

        # coordinates
        self.lat = ""
        self.long = ""
        self.confidence_score = 0.0


class Contour:
    def __init__(self, contour_data=None):
        self.data = contour_data
        self.text = ""
        self.font_attrs = []

        if contour_data is not None:
            [self.x, self.y, self.w, self.h] = cv2.boundingRect(contour_data)
            self.x_mid = self.x + self.w / 2
            self.y_mid = self.y + self.h / 2
        else:
            self.x = 0
            self.y = 0
            self.w = 0
            self.h = 0

            self.x_mid = 0
            self.y_mid = 0

# a special exception class for exceptions generated by registry processor and child classes
class RegistryProcessorException(Exception):
    def __init__(self, value):
        self.value = value
    def __str__(self):
        return self.value

# thread safe versions of opencv's imread and imwrite

cv2_io_mutex = Lock()

def cv2_imread_safe(*args, **kwargs):
    cv2_io_mutex.acquire()
    result = cv2.imread(*args, **kwargs)
    cv2_io_mutex.release()

    return result

def cv2_imwrite_safe(*args, **kwargs):
    cv2_io_mutex.acquire()
    result = cv2.imwrite(*args, **kwargs)
    cv2_io_mutex.release()

    return result

class RegistryProcessor(object):

    # lambdas were no longer sufficient with multiple threads for some reason
    def _image_height(self):
        return self._image.shape[0]
    def _image_width(self):
        return self._image.shape[1]

    def _expand_bb(self, x, y, w, h):
        return \
        (x - int(self._image_width() * self.bb_expansion_percent / 2), \
         y - int(self._image_height() * self.bb_expansion_percent / 2), \
         w + int(self._image_width() * self.bb_expansion_percent / 2), \
         h + int(self._image_height() * self.bb_expansion_percent / 2))

    def _geoquery_log_fn(self):
        assert(self.state != "" and self.year != -1)
        return os.path.join(self.outdir, "unsucessful_geo-queries_%s_%d.log" % (self.state, self.year))

    # when RegistryProcessor object is copied into a new subprocess
    # our tess api object needs to be recreated so we made a function to do it
    def make_tess_api(self):
        self._tess_api = TessBaseAPI()

        # set some tesseract parameters
        if not self._tess_api.SetVariable("tessedit_pageseg_mode", "6"):
            print >> sys.stderr, "error setting psm"
        if not self._tess_api.SetVariable("tessedit_char_whitelist", "\"#%&'()*+,-./\\0123456789:;ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz"):
            print >> sys.stderr, "error setting char whitelist"

    # constructor no longer takes state & year args, use initialize_state_year() instead
    def __init__(self):
        self._tess_api = None

        # initialize self._tess_api
        self.make_tess_api()

        self._image = None
        self._thresh = None

        # image processing parameters (these are example values)
        self.kernel_shape = (10, 3)
        self.thresh_value = 60  # higher = more exposure (max = 255)
        self.iterations = 8
        self.match_rate = 0.7  # lower = more lenient
        self.indent_width = 0.025  # indent width as % of contour width

        # percent of image width and height to add to bounding box width and height of contours (improves ocr accuracy)
        # higher = bigger bounding box
        self.bb_expansion_percent = 0.012

        self.columns_per_page = 2
        self.pages_per_image = 1
        self.page_boundary = -1 # coordinates of page boundary on current image (only used if self.pages_per_image == 2)

        self.std_thresh = 1  # number of standard deviations beyond which contour is no longer considered part of column

        # performance & accuracy stats
        self.ocr_confidence_sum = 0
        self.num_words = 0
        self.num_geo_successes = 0
        self.num_geo_attempts = 0
        self.per_image_business_counts = []

        self.draw_debug_images = False  # turning this on can help with debugging
        self.assume_pre_processed = False  # assume images are preprocessed so to not waste extra computational power
        self.line_color = (130, 130, 130)  # NOTE: line color for debug images, must be visible in grayscale
        self.outdir = "."  # dir to write debug images, logs and tsv results

        self.businesses = []

        self.state = ""
        self.year = -1

    #initialize this object for the specified state and year (if not done already)
    def initialize_state_year(self, state, year):

        # initialize city lookup for this state
        self.state = state
        self._city_lists_path = os.path.join(_datadir, "%s-cities.txt" % self.state)
        self._city_detector = CityDetector()
        self._city_detector.load_cities(self._city_lists_path)

        self.year = year

        # load config file from this state & year
        basepath = georeg.__path__[0]
        filename = str(year) + '.cfg'
        path = os.path.abspath(os.path.join(basepath, "configs", state, filename))
        if os.path.exists(path):
            self.load_settings_from_cfg(path)
        else:
            print >> sys.stderr, "configuration file not found"

    def process_image(self, path):
        """this is a wrapper for _process_image() which catches exceptions and reports them"""
        try:
            self.__process_image(path)
        except RegistryProcessorException as e:
            print >>sys.stderr, "error: %s, skipping" % e

    # this function should not need to be overriden
    def __process_image(self, path):
        """process a registry image and store results in the businesses member,
        don't call this directly call process_image() instead"""

        self.businesses = [] # reset businesses list

        self._image = cv2_imread_safe(path, cv2.IMREAD_GRAYSCALE)

        _,contours,_ = self._get_contours(self.kernel_shape, self.iterations, True)
        contours = [Contour(c) for c in contours]

        #remove noise from edge of image
        if not self.assume_pre_processed:
            contours = self._remove_edge_contours(contours)

        if self.draw_debug_images:
            canvas = np.zeros(self._image.shape,self._image.dtype)
            cv2.drawContours(canvas,[c.data for c in
                contours],-1,self.line_color,-1)
            cv2_imwrite_safe(os.path.join(self.outdir, "closed.tiff"), canvas)

        clustering = self._find_column_locations(contours)
        column_contours, noncolumn_contours = self._make_contour_columns(contours, clustering)

        noncolumn_contours = self._get_noncolumn_contours_of_interest(noncolumn_contours)

        contoured = None

        if self.draw_debug_images:
            contoured = self._image.copy()

        # set the image tesseract will work with
        self._tess_api.SetImage(self._thresh)

        # OCR our column contours
        for contour in itertools.chain.from_iterable(column_contours):
            x,y,w,h = self._expand_bb(contour.x,contour.y,contour.w,contour.h)

            if self.draw_debug_images:
                # draw bounding box on original image
                cv2.rectangle(contoured,(x,y),(x+w,y+h),self.line_color,5)

            # specify region tesseract should ocr
            self._tess_api.SetRectangle(x,y,w,h)
            contour.text, contour.text_attrs = self._tess_api.GetTextWithAttrs()

            total_conf, num_words = self._tess_api.TotalConfidence()

            self.ocr_confidence_sum += total_conf
            self.num_words += num_words

        # OCR our noncolumn contours of interest
        for contour in noncolumn_contours:
            x, y, w, h = self._expand_bb(contour.x, contour.y, contour.w, contour.h)

            if self.draw_debug_images:
                # draw bounding box on original image
                cv2.rectangle(contoured, (x, y), (x + w, y + h), self.line_color, 5)

            # specify region tesseract should ocr
            self._tess_api.SetRectangle(x, y, w, h)
            contour.text, contour.text_attrs = self._tess_api.GetTextWithAttrs()

        if self.draw_debug_images:
            # write original image with added contours to disk
            cv2_imwrite_safe(os.path.join(self.outdir, "contoured.tiff"), contoured)

        # get our custom call args if any
        call_args = self._define_contour_call_args(column_contours, noncolumn_contours)

        num_businesses_found = 0

        if not os.path.exists(self._geoquery_log_fn()): # if the log doesn't exist make it
            file = open(self._geoquery_log_fn(), "w")
            file.close()

        # here we process all of our contours
        for args in call_args:
            # if args is indeed multiple arguments then we'll expand them
            if isinstance(args, collections.Sequence) and not isinstance(args, basestring):
                business = self._process_contour(*args)
                contour_txt = args[0]
            else: # otherwise we treat it like one argument
                business = self._process_contour(args)
                contour_txt = args

            if business is None:
                continue

            # record business
            self.businesses.append(business)

            # if address was found attempt to geocode
            if business.address:
                num_businesses_found += 1
                self.num_geo_attempts += 1

                result = geo.geocode_business(business, self.state)
                if not result:
                    with open(self._geoquery_log_fn(), "a") as file:
                        file.write("Unsuccessful geo-query from %s:\n" % os.path.basename(path))
                        file.write("name: \"%s\" address: \"%s\", city: \"%s\", zip: \"%s\"\n" % (
                            business.name, business.address, business.city, business.zip))
                        file.write("=" * 100 + "\n")
                        file.write("Contour Text:\n")
                        file.write("=" * 100 + "\n")
                        file.write(contour_txt.strip() + "\n")  # write contour text
                        file.write("=" * 100 + "\n\n")
                else:
                    self.num_geo_successes += 1

        # record the number of businesses found in this image
        self.per_image_business_counts.append(num_businesses_found)

    def _get_noncolumn_contours_of_interest(self, noncolumn_contours):
        """
        override this if your class is interested in non-column contours (i.e. headers)
        :param noncolumn_contours: noncolumn contours found
        :return: a list of noncolumn contours we are inerested in
        """
        return []

    def _define_contour_call_args(self, column_contours, noncolumn_contours):
        """
        override this if _process_contour() needs to be called with additional arguments (like the text of the header it is under)
        :param column_contours: a 2d list were each column is a column and each row is a contour (of type 'Contour')
        :param noncolumn_contours: a 1d list of all non-column contours in the image (of type 'Contour')
        :return: a list of argument tuples that will each be passed to a _process_contour() call
                (1st arg must be the contour text, and 2nd must be the contour text attributes)
        """
        return ((c.text, c.text_attrs) for c in itertools.chain.from_iterable(column_contours))

    def _process_contour(self, contour_txt, countor_font_attrs, *args):
        """
        Process the text of a contour to make a business object,
        may also be passed info about non-column contours if
        _get_noncolumn_contours_of_interest() and _define_contour_call_args()
        are overriden
        :param contour_txt: the text in the contour
        :param args: optional additional information
        :return: a business object representing the contour's text or None
        """
        raise NotImplementedError

    def remove_geoquery_log(self):
        """if this isn't called the existing file will simply be appended to"""
        if (os.path.exists(self._geoquery_log_fn())):
            os.remove(self._geoquery_log_fn())

    def total_ocr_confidence(self):
        """returns (total confidence, number of words) for getting an average over multiple runs"""
        return (self.ocr_confidence_sum, self.num_words)

    def mean_ocr_confidence(self):
        """returns mean confidence so far or -1 if OCR has not been used yet"""
        return self.ocr_confidence_sum * 1.0 / self.num_words if self.num_words > 0 else -1

    #TODO: reimplement success rate tracking once our geocoder returns results below 75%
    # i.e. return mean ocr confidence instead of success rate
    def geocoder_success_rate(self):
        """returns geocoder success rate or -1 if not valid"""
        return (self.num_geo_successes * 1.0 / self.num_geo_attempts) * 100 if self.num_geo_attempts > 0 else -1

    def businesses_per_image_std(self):
        """returns the standard deviation of the number of businesses found per image or -1 if not valid,
        a high std means we are likely not finding all business contours"""

        if len(self.per_image_business_counts) == 0:
            return -1

        mean_bus_count = sum(self.per_image_business_counts) * 1.0 / len(self.per_image_business_counts)
        dists_from_mean = ((mean_bus_count - c)**2 for c in self.per_image_business_counts)
        variance = sum(dists_from_mean) / len(self.per_image_business_counts)

        return sqrt(variance)

    def reset_stats(self):
        """resets all performance stats being recorded by registry_processor"""
        self.ocr_confidence_sum = 0
        self.num_words = 0
        self.num_geo_successes = 0
        self.num_geo_attempts = 0
        self.per_image_business_counts = []

    def load_from_tsv(self, path):
        """load self.businesses from a tsv file where they were previously saved"""

        self.businesses = [] # reset businesses list

        # mini function for loading an individual business file
        def load_businesses(path):
            with open(path, "r") as file:
                file_reader = csv.reader(file, delimiter="\t")
                for row in file_reader:
                    business = Business()

                    [business.category, business.name, business.address,
                     business.city, business.zip, business.emp, business.sales,
                     business.cat_desc, business.bracket, business.lat,
                     business.long, business.confidence_score] = row

                    # cast to float
                    business.confidence_score = float(business.confidence_score)

                    self.businesses.append(business)

        # load normal businesses
        load_businesses(path)

    def record_to_tsv(self, path, mode = 'w'):
        """record business registries to tsv, opened with file access mode: mode"""

        with open(path, mode) as file:
            file_writer = csv.writer(file, delimiter ="\t")

            for business in self.businesses:
                entry = [business.category, business.name, business.address,
                         business.city, business.zip, business.emp, business.sales,
                         business.cat_desc, business.bracket, business.lat, business.long,
                         business.confidence_score]

                file_writer.writerow(entry)

    def load_settings_from_cfg(self, path):
        # Set default values.
        cp = ConfigParser.ConfigParser({
                'kernel_shape_x': str(self.kernel_shape[0]),
                'kernel_shape_y': str(self.kernel_shape[1]),
                'thresh_value': str(self.thresh_value),
                'iterations': str(self.iterations),
                'match_rate': str(self.match_rate),
                'columns_per_page': str(self.columns_per_page),
                'pages_per_image': str(self.pages_per_image),
                'bb_expansion_percent': str(self.bb_expansion_percent), 
                'indent_width': str(self.indent_width),
                'std_thresh': str(self.std_thresh),
            })
        cp.read(path)

        # Get values from config file.
        self.kernel_shape = (int(cp.get('RegistryProcessor','kernel_shape_x')),int(cp.get('RegistryProcessor','kernel_shape_y')))
        self.thresh_value = cp.getint('RegistryProcessor','thresh_value')
        self.iterations = cp.getint('RegistryProcessor','iterations')
        self.match_rate = cp.getfloat('RegistryProcessor','match_rate')
        self.columns_per_page = cp.getint('RegistryProcessor','columns_per_page')
        self.pages_per_image = cp.getint('RegistryProcessor','pages_per_image')
        self.bb_expansion_percent = cp.getfloat('RegistryProcessor','bb_expansion_percent')
        self.indent_width = cp.getfloat('RegistryProcessor','indent_width')
        self.std_thresh = cp.getfloat('RegistryProcessor','std_thresh')

    def save_settings_to_cfg(self, path):
        cp = ConfigParser.SafeConfigParser()

        cp.add_section('RegistryProcessor')
        cp.set('RegistryProcessor','kernel_shape_x',str(self.kernel_shape[0]))
        cp.set('RegistryProcessor','kernel_shape_y',str(self.kernel_shape[1]))
        cp.set('RegistryProcessor','thresh_value',str(self.thresh_value))
        cp.set('RegistryProcessor','iterations',str(self.iterations))
        cp.set('RegistryProcessor','match_rate',str(self.match_rate))
        cp.set('RegistryProcessor','columns_per_page',str(self.columns_per_page))
        cp.set('RegistryProcessor','pages_per_image',str(self.pages_per_image))
        cp.set('RegistryProcessor','bb_expansion_percent',str(self.bb_expansion_percent))
        cp.set('RegistryProcessor','indent_width',str(self.indent_width))
        cp.set('RegistryProcessor','std_thresh',str(self.std_thresh))

        with open(path,'w') as cfg_file:
            cp.write(cfg_file)

    def _remove_edge_contours(self, contours):
        """remove contours that touch the edge of image
        and crops self._image and self._thresh to an
        appropriate size"""

        filtered_contours = []

        for contour in contours:
            if (contour.x == 1 or contour.x + contour.w == self._image_width() - 1) or \
            (contour.y == 1 or contour.y + contour.h == self._image_height() - 1):
                continue

            filtered_contours.append(contour)

        if len(filtered_contours) == 0:
            raise RegistryProcessorException("No non-background contours found, check debug images")

        # create cropped version of image
        super_contour = np.concatenate([c.data for c in filtered_contours])
        [x,y,w,h] = cv2.boundingRect(super_contour)

        # make bounding box bigger
        x,y,w,h = self._expand_bb(x,y,w,h)

        self._image = self._image[y:y+h,x:x+w]
        self._thresh = self._thresh[y:y+h,x:x+w]

        # apply cropping offset to contours
        for c in contours:
            c.x -= x
            c.x_mid -= x
            c.y -= y
            c.y_mid -= y
            # apply cropping offset to each point in contours
            for p in c.data:
                p[0][0] -= x
                p[0][1] -= y

        return filtered_contours

    def _get_contours(self, kernel_shape, iter, make_new_thresh = True):
        """performs a close operation on self._image then extracts the contours"""

        if make_new_thresh: # if asked then we make a new thresh image
            if not self.assume_pre_processed:
                _,self._thresh = cv2.threshold(self._image,self.thresh_value,255,cv2.THRESH_BINARY_INV) # threshold
            else:
                _,self._thresh = cv2.threshold(self._image,0,255,cv2.THRESH_BINARY_INV) # threshold with 0 threshold value

        kernel = cv2.getStructuringElement(cv2.MORPH_RECT,kernel_shape)
        closed = cv2.morphologyEx(self._thresh,cv2.MORPH_CLOSE,kernel,iterations = iter) # close

        # perform a small open operation to remove noise
        closed = cv2.morphologyEx(closed,cv2.MORPH_OPEN,kernel,iterations = iter / 3)

        return cv2.findContours(closed,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE) # get contours

    def _find_column_locations(self, contours):
        """find column column locations, and page boundary if two pages
        (returns column locations)"""

        # create array of coords for left and right edges of contours
        coords = [[contour.x, contour.x + contour.w] for contour in contours]
        coords_arr = np.array(coords)

        # use k-means clustering to get column boundaries for expected # of cols
        num_cols = self.columns_per_page * self.pages_per_image
        k_means = KMeans(n_clusters=num_cols)

        if len(coords_arr) < num_cols:
            raise RegistryProcessorException("Number of contours detected fewer than number of expected columns")

        clustering = k_means.fit(coords_arr)

        self.page_boundary = -1
        if self.pages_per_image == 2:  # if there are two pages find the page boundary
            sorted_cols = sorted(clustering)
            self.page_boundary = (sorted_cols[self.columns_per_page - 1][0] +
                                  sorted_cols[self.columns_per_page][0]) / (2 * 1.0)

        # draw columns lines and clusters
        if self.draw_debug_images:
            # generate a different color for each cluster
            cluster_colors = [[x]*3 for x in np.linspace(0,255,num=num_cols+2)[1:-1]]

            # use left and right coords of clusters to draw columns
            canvas = self._thresh.copy()
            for ix, column_l in enumerate(clustering.cluster_centers_):
                left, right = int(column_l[0]), int(column_l[1])
                cv2.line(canvas,(left, 0),(left,
                    self._image_height()),cluster_colors[ix],20)
                cv2.line(canvas,(right, 0),(right,
                    self._image_height()),cluster_colors[ix],20)

            # draw column lines to file
            cv2_imwrite_safe(os.path.join(self.outdir, "column_lines.tiff"), canvas)

            # draw contour widths in color of assigned cluster
            canvas = self._thresh.copy()
            for ix, contour in enumerate(contours):
                col = cluster_colors[clustering.labels_[ix]]
                left, right, y = contour.x, contour.x + contour.w, contour.y_mid
                cv2.circle(canvas,(left, y),20,col,35)
                cv2.circle(canvas,(right, y),20,col,35)
                cv2.line(canvas,(left, y),(right, y),col,10)

            # draw clustered column widths to file
            cv2_imwrite_safe(os.path.join(self.outdir, "clusters.tiff"), canvas)

        return clustering

    def _make_contour_columns(self, contours, clustering):
        """makes contour columns based on column locations
           return: contour_columns, noncolumn_contours
           (column contours are sorted by column and position)"""

        column_contours = []
        non_column_contours = []

        # sort contours by clusters
        cluster_groups = sorted(zip(clustering.labels_, contours))

        # iterate through column groups, deciding which contours are valid
        for col_ix, cluster_group in itertools.groupby(cluster_groups, lambda x: x[0]):

            # coords of column
            col_loc = clustering.cluster_centers_[col_ix]

            cluster_contours = [c for _, c in cluster_group]

            # x-coords of contours
            contour_locs = [[c.x, c.x + c.w] for c in cluster_contours]
            # calculate standard deviation of contour x-coords
            col_std = np.std(contour_locs)

            # only keep contours if less than threshold std devs from column
            keep_contours = []
            for contour_ix, contour in enumerate(cluster_contours):
                dist = abs(np.linalg.norm(contour_locs[contour_ix] - col_loc))
                if dist < self.std_thresh * col_std:
                    keep_contours.append(contour)
                else:
                    non_column_contours.append(contour)

            column_contours.append(keep_contours)

        # sort column and contour by position
        sorted_column_contours = []
        sorted_columns = sorted(enumerate(column_contours),key=lambda x: 
                                 clustering.cluster_centers_[x[0]][0])
        for i, column in sorted_columns:
            sorted_column_contours.append(sorted(column,key=attrgetter('y')))

        return sorted_column_contours, non_column_contours


class DummyTextRecorder(RegistryProcessor):
    def __init__(self):
        super(DummyTextRecorder, self).__init__()

        self.registry_txt = ""

    def _process_contour(self, contour_txt):
        self.registry_txt += "\n" + contour_txt

        return None

    def record_to_tsv(self, path, mode = 'w'):
        with open(path, mode) as file:
            file.write(self.registry_txt)
